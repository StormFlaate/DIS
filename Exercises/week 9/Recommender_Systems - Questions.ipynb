{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Exercise 8: Recommender Systems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Libaries needed: scikit-surprise, pandas, sklearn, numpy. \n",
    "To install `scikit-surprise`:**\n",
    "```\n",
    "conda install -c conda-forge scikit-surprise\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise, we will be proceeding in two stages. The first stage is where we get into the details of how to build our own recommender system to recommend movies to users. In the second stage, we will be an existing library, specialized for recommender systems, which provides more powerful options. We will be testing it on the task of recommending jokes to users. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make sure we have all the requirements ready. In this exercise, you should be filling the empty code sections, marked as `TODO:`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import surprise\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Task 1: Exploring the MovieLens dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part, we'll be using the [MovieLens dataset](https://grouplens.org/datasets/movielens/). This dataset is based on [movielens.org](https://movielens.org/), a site where users can get movie recommendations.\n",
    "\n",
    "Our first step is to load the relevant file of the dataset, which you can find in the file `u.data` (on the path `data/ml-100k/u.data`).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "header = ['user_id', 'item_id', 'rating', 'timestamp']\n",
    "df = pd.read_csv('data/ml-100k/u.data', sep='\\t', names=header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>196</td>\n",
       "      <td>242</td>\n",
       "      <td>3</td>\n",
       "      <td>881250949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>186</td>\n",
       "      <td>302</td>\n",
       "      <td>3</td>\n",
       "      <td>891717742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22</td>\n",
       "      <td>377</td>\n",
       "      <td>1</td>\n",
       "      <td>878887116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>244</td>\n",
       "      <td>51</td>\n",
       "      <td>2</td>\n",
       "      <td>880606923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>166</td>\n",
       "      <td>346</td>\n",
       "      <td>1</td>\n",
       "      <td>886397596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>298</td>\n",
       "      <td>474</td>\n",
       "      <td>4</td>\n",
       "      <td>884182806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>115</td>\n",
       "      <td>265</td>\n",
       "      <td>2</td>\n",
       "      <td>881171488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>253</td>\n",
       "      <td>465</td>\n",
       "      <td>5</td>\n",
       "      <td>891628467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>305</td>\n",
       "      <td>451</td>\n",
       "      <td>3</td>\n",
       "      <td>886324817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>6</td>\n",
       "      <td>86</td>\n",
       "      <td>3</td>\n",
       "      <td>883603013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>62</td>\n",
       "      <td>257</td>\n",
       "      <td>2</td>\n",
       "      <td>879372434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>286</td>\n",
       "      <td>1014</td>\n",
       "      <td>5</td>\n",
       "      <td>879781125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>200</td>\n",
       "      <td>222</td>\n",
       "      <td>5</td>\n",
       "      <td>876042340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>210</td>\n",
       "      <td>40</td>\n",
       "      <td>3</td>\n",
       "      <td>891035994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>224</td>\n",
       "      <td>29</td>\n",
       "      <td>3</td>\n",
       "      <td>888104457</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    user_id  item_id  rating  timestamp\n",
       "0       196      242       3  881250949\n",
       "1       186      302       3  891717742\n",
       "2        22      377       1  878887116\n",
       "3       244       51       2  880606923\n",
       "4       166      346       1  886397596\n",
       "5       298      474       4  884182806\n",
       "6       115      265       2  881171488\n",
       "7       253      465       5  891628467\n",
       "8       305      451       3  886324817\n",
       "9         6       86       3  883603013\n",
       "10       62      257       2  879372434\n",
       "11      286     1014       5  879781125\n",
       "12      200      222       5  876042340\n",
       "13      210       40       3  891035994\n",
       "14      224       29       3  888104457"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[:15]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first check the number of users and movies in the dataset to get an idea of the scale we're dealing with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of users = 943 | Number of movies = 1682\n"
     ]
    }
   ],
   "source": [
    "# TODO: get the number of users and itens\n",
    "n_users = df['user_id'].nunique()\n",
    "n_items = df['item_id'].nunique()\n",
    "print ('Number of users = ' + str(n_users) + ' | Number of movies = ' + str(n_items))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also get an overall view of the dataset as below. Notice how the ratings range from a minimum of 1 to a maximum of 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>100000.00</td>\n",
       "      <td>100000.00</td>\n",
       "      <td>100000.00</td>\n",
       "      <td>100000.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>462.48</td>\n",
       "      <td>425.53</td>\n",
       "      <td>3.53</td>\n",
       "      <td>883528851.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>266.61</td>\n",
       "      <td>330.80</td>\n",
       "      <td>1.13</td>\n",
       "      <td>5343856.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>874724710.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>254.00</td>\n",
       "      <td>175.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>879448709.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>447.00</td>\n",
       "      <td>322.00</td>\n",
       "      <td>4.00</td>\n",
       "      <td>882826944.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>682.00</td>\n",
       "      <td>631.00</td>\n",
       "      <td>4.00</td>\n",
       "      <td>888259984.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>943.00</td>\n",
       "      <td>1682.00</td>\n",
       "      <td>5.00</td>\n",
       "      <td>893286638.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        user_id   item_id    rating    timestamp\n",
       "count 100000.00 100000.00 100000.00    100000.00\n",
       "mean     462.48    425.53      3.53 883528851.49\n",
       "std      266.61    330.80      1.13   5343856.19\n",
       "min        1.00      1.00      1.00 874724710.00\n",
       "25%      254.00    175.00      3.00 879448709.50\n",
       "50%      447.00    322.00      4.00 882826944.00\n",
       "75%      682.00    631.00      4.00 888259984.00\n",
       "max      943.00   1682.00      5.00 893286638.00"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.float_format', lambda x: '%.2f' % x)\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the data is loaded, we proceed to splitting it into a training set and a testing set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_data, test_data = train_test_split(df, test_size=0.25, random_state= 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>98980</th>\n",
       "      <td>811</td>\n",
       "      <td>901</td>\n",
       "      <td>4</td>\n",
       "      <td>886377771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69824</th>\n",
       "      <td>804</td>\n",
       "      <td>755</td>\n",
       "      <td>3</td>\n",
       "      <td>879445305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9928</th>\n",
       "      <td>52</td>\n",
       "      <td>287</td>\n",
       "      <td>5</td>\n",
       "      <td>882922357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75599</th>\n",
       "      <td>735</td>\n",
       "      <td>181</td>\n",
       "      <td>4</td>\n",
       "      <td>876698604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95621</th>\n",
       "      <td>897</td>\n",
       "      <td>96</td>\n",
       "      <td>5</td>\n",
       "      <td>879990430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6265</th>\n",
       "      <td>216</td>\n",
       "      <td>231</td>\n",
       "      <td>2</td>\n",
       "      <td>880245109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54886</th>\n",
       "      <td>343</td>\n",
       "      <td>276</td>\n",
       "      <td>5</td>\n",
       "      <td>876403078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76820</th>\n",
       "      <td>437</td>\n",
       "      <td>475</td>\n",
       "      <td>3</td>\n",
       "      <td>880140288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>284</td>\n",
       "      <td>322</td>\n",
       "      <td>3</td>\n",
       "      <td>885329671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15795</th>\n",
       "      <td>222</td>\n",
       "      <td>200</td>\n",
       "      <td>3</td>\n",
       "      <td>878181647</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>75000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       user_id  item_id  rating  timestamp\n",
       "98980      811      901       4  886377771\n",
       "69824      804      755       3  879445305\n",
       "9928        52      287       5  882922357\n",
       "75599      735      181       4  876698604\n",
       "95621      897       96       5  879990430\n",
       "...        ...      ...     ...        ...\n",
       "6265       216      231       2  880245109\n",
       "54886      343      276       5  876403078\n",
       "76820      437      475       3  880140288\n",
       "860        284      322       3  885329671\n",
       "15795      222      200       3  878181647\n",
       "\n",
       "[75000 rows x 4 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's create the user-item matrices, one for training and another for testing. Each matrix should be a 2D numpy array, with each row corresponding to a user and each column to a movie. A non-zero cell in the matrix is the rating given by the user to the movie (zeros are for the case of no corresponding rating).\n",
    "\n",
    "**Notice that the user ids and item ids start from 1, so the index (0,0) in your matrix should correspond to `user_id` of 1 and `item_id` of 1.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO fill the code to produce a data matrix\n",
    "def create_data_matrix(data,n_users,n_items):\n",
    "    \"\"\"\n",
    "        This function should return a numpy matrix with a shape (n_users, n_items). \n",
    "        Each entry is the rating given by the user to the item\n",
    "    \"\"\"\n",
    "    data_matrix = np.zeros((n_users, n_items))\n",
    "    for index, row in data.iterrows():\n",
    "        user_id = row['user_id']\n",
    "        item_id= row['item_id']\n",
    "        rating = row['rating']\n",
    "        data_matrix[user_id-1, item_id-1] = rating\n",
    "    \n",
    "    return data_matrix\n",
    "\n",
    "train_data_matrix= create_data_matrix(train_data, n_users, n_items)\n",
    "test_data_matrix= create_data_matrix(test_data, n_users, n_items)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can check how our matrices look like at this point. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_data_matrix\n",
      "[[0. 3. 4. ... 0. 0. 0.]\n",
      " [4. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [5. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 5. 0. ... 0. 0. 0.]]\n",
      "test_data_matrix\n",
      "[[5. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print('train_data_matrix')\n",
    "print(train_data_matrix)\n",
    "print('test_data_matrix')\n",
    "print(test_data_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2: Item-based Collaborative Filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've prepared our data, the next mission we have is to create a recommender system following the paradigm of Item-based Collaborative Filtering. In this case, this is translated into \"Users who liked this item (movie) also liked …\". \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to make predictions, we will apply following formula, where \n",
    "$N_I(a)$ is the set of neighbors of item $a$, and $b$ is an item rated by user $x$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "{r}_{x}(a) =  \\frac{\\sum\\limits_{b \\in N_{I}(a)} sim(a, b) r_{x}(b)}{\\sum\\limits_{b \\in N_{I}(a)}|sim(a, b)|}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a building block, we'll first write the code for the similarity $sim(a,b)$ metric between each two item vectors in our training matrix. In this case, we will use the cosine similarity metric. The output should be an `n_items` by `n_items` symmetric 2D numpy matrix with the similarity between each couple of items.\n",
    "\n",
    "**Note**: In this exercise, there are always two ways of achieving the same goal: a slow one via `for` loops and another by benefiting from numpy's speed in matrix operations. Feel free to improve your starting solution to a faster one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.29431963, 0.25248099, ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.29431963, 1.        , 0.18855956, ..., 0.        , 0.09099269,\n",
       "        0.        ],\n",
       "       [0.25248099, 0.18855956, 1.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.        , 0.        , 0.        , ..., 1.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.09099269, 0.        , ..., 0.        , 1.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        1.        ]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO fill the code to compute the similarity matrix\n",
    "from sklearn.metrics.pairwise import pairwise_distances\n",
    "# this matrix shows the similarity between items\n",
    "item_similarity = 1-pairwise_distances(train_data_matrix.T, metric='cosine')\n",
    "# check how the matrix looks like\n",
    "item_similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll use the similarity matrix in the above formula to obtain the predicted ranking for each item `a`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "943it [11:57,  1.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3.84636515 3.         4.         ... 4.09576166 3.84555021 4.        ]\n",
      " [4.         3.99015099 3.94449343 ... 3.7536442  3.83830292 3.        ]\n",
      " [2.74167162 2.76153256 2.75428409 ... 3.01728956 2.93171602 1.        ]\n",
      " ...\n",
      " [5.         4.1299914  4.12830226 ... 4.         3.88259423 5.        ]\n",
      " [4.38546083 4.41069101 4.37404141 ... 4.19056099 4.3596925  1.        ]\n",
      " [3.53536005 5.         3.53042866 ... 2.         3.55127837 3.        ]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# TODO: Fill the code for predicting the ratings. \n",
    "# The output is a numpy matrix with the dimensions ((n_users,n_items)) \n",
    "# and with the corresponding ranking at each cell.\n",
    "def item_based_predict(ratings, similarity):\n",
    "    pred = np.zeros(ratings.shape)\n",
    "    numb_users, numb_ratings = ratings.shape\n",
    "    for user_id, user_ratings in tqdm(enumerate(ratings)):\n",
    "        for movie_i, movie_rating in enumerate(user_ratings):\n",
    "            # Then the movie is not rated yet\n",
    "            if movie_rating == 0:\n",
    "                movie_sum = 0\n",
    "                movie_count = 0\n",
    "                for i in range(numb_ratings):\n",
    "                    cur_rating = user_ratings[i]\n",
    "                    if cur_rating > 0:\n",
    "                        movie_sum += cur_rating*similarity[movie_i,i]\n",
    "                        movie_count += np.abs(similarity[movie_i,i])\n",
    "                if movie_count > 0:\n",
    "                    pred_rating = movie_sum/movie_count\n",
    "                    pred[user_id, movie_i] = pred_rating\n",
    "                else:\n",
    "                    pred[user_id, movie_i] = np.random.randint(1,6, dtype=int)\n",
    "            else:\n",
    "                pred[user_id, movie_i] = ratings[user_id, movie_i]\n",
    "                \n",
    "    return pred\n",
    "\n",
    "item_prediction = item_based_predict(train_data_matrix, item_similarity)\n",
    "print(item_prediction)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3: User-based Collaborative Filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next mission we have is to create a recommender system following the paradigm of User-based Collaborative Filtering. In this case, this is translated into \"Users who are similar to you also liked…\". "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to make predictions, we will apply following formula, where $N_U(x)$ is the set of neighbors of user x and $a$ is an item not rated by x.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "{r}_{x}(a) = \\bar{r}_{x} + \\frac{\\sum\\limits_{y \\in N_{U}(x)} sim(x, y) (r_{y}(a) - \\bar{r}_{y})}{\\sum\\limits_{y \\in N_{U}(x)}|sim(x, y)|}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to above, we will first compute the distances between the users in our training matrix, using cosine similarity. The output should be an `n_users` by `n_users` symmetric 2D numpy matrix with the similarity between each couple of users."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(943, 943)\n",
      "[[1.         0.14336926 0.03241686 ... 0.0896044  0.08784797 0.31415893]\n",
      " [0.14336926 1.         0.10759069 ... 0.08110762 0.14570123 0.07977339]\n",
      " [0.03241686 0.10759069 1.         ... 0.02386986 0.10703166 0.        ]\n",
      " ...\n",
      " [0.0896044  0.08110762 0.02386986 ... 1.         0.06944821 0.06727982]\n",
      " [0.08784797 0.14570123 0.10703166 ... 0.06944821 1.         0.1171645 ]\n",
      " [0.31415893 0.07977339 0.         ... 0.06727982 0.1171645  1.        ]]\n"
     ]
    }
   ],
   "source": [
    "# TODO fill the code to compute the similarity matrix\n",
    "user_similarity = 1-pairwise_distances(train_data_matrix, metric='cosine')\n",
    "\n",
    "# print the shape as a sanity check\n",
    "print(user_similarity.shape)\n",
    "\n",
    "# check how the matrix looks like\n",
    "print(user_similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 1682/1682 [00:59<00:00, 28.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3.97307747 3.70688477 4.08655616 ... 2.48106061 3.6819321  3.6969697 ]\n",
      " [3.97307747 3.57863946 3.33600387 ... 2.62130021 3.82217171 3.8372093 ]\n",
      " [3.00018498 2.42596942 2.26508003 ... 1.52827696 2.72914845 2.74418605]\n",
      " ...\n",
      " [3.69370818 3.94136387 3.80024698 ... 2.97159091 4.17246241 4.1875    ]\n",
      " [4.56501421 4.08655616 3.88805008 ... 3.08409091 4.28496241 4.3       ]\n",
      " [3.70688477 4.08655616 3.08881469 ... 3.40944882 3.39441122 3.40944882]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# TODO: Fill the code for predicting the ratings. \n",
    "def user_based_predict(ratings, similarity):\n",
    "    pred = np.zeros(ratings.shape)\n",
    "    numb_users, numb_items = ratings.shape\n",
    "    avg_vec = np.true_divide(ratings.sum(1),(ratings!=0).sum(1))\n",
    "    \n",
    "    for a in tqdm(range(numb_items)):\n",
    "        for x in range(numb_users):\n",
    "            if ratings[x, a] == 0:\n",
    "                \n",
    "                avg_x = avg_vec[x]\n",
    "                avg_vec_rest = np.append(avg_vec[:x], avg_vec[x+1:])\n",
    "                item_a_ratings = np.append(ratings[:,a][:x], ratings[:,a][x+1:])\n",
    "                sim_vec = np.delete(similarity[x],x)\n",
    "                \n",
    "                mask = (item_a_ratings != 0)\n",
    "                # Only do the subtraction where both A1 & A2 are nonzero,\n",
    "                # otherwise copy the A2 value\n",
    "                over = np.where(mask, sim_vec*(item_a_ratings-avg_vec_rest), 0).sum()\n",
    "                under = np.absolute(np.where(mask, sim_vec, 0)).sum()\n",
    "                \n",
    "                if under > 0:\n",
    "                    pred[x, a] = avg_x + over/under\n",
    "                else: \n",
    "                    pred[x, a] = avg_x \n",
    "            \n",
    "            else:\n",
    "                pred[x, a] = ratings[x, a]\n",
    "  \n",
    "            if under > 0:\n",
    "                pred[x, a] = avg_x + over/under\n",
    "            else:\n",
    "                pred[x, a] = avg_x\n",
    "\n",
    "    return pred\n",
    "#             avg_y = np.true_divide(ratings[y].sum(),(ratings[y]!=0).sum())\n",
    "user_prediction = user_based_predict(train_data_matrix, user_similarity)\n",
    "print(user_prediction)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Task 4: Evaluating Our Recommenders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be evaluating our recommenders using Root Mean Squared Error (RMSE). In the formula below, $r_i$ is the true rating and $\\hat{r_i}$ is the predicted one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "\\mathit{RMSE} =\\sqrt{\\frac{1}{N} \\sum_i (r_i -\\hat{r_i})^2}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: add the code for computing RMSE for user and item based methods\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "def rmse(prediction, ground_truth):\n",
    "    ...\n",
    "\n",
    "print ('User-based CF RMSE: ' + str(rmse(user_prediction, test_data_matrix)))\n",
    "print ('Item-based CF RMSE: ' + str(rmse(item_prediction, test_data_matrix)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 5: Introducing Surprise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part, we will move to using [Surprise](http://surpriselib.com/), a full-fledged python library, specialized for recommender systems. The goal is to get exposed to such more powerful libraries that can automate a lot of the manual work we had to do above.\n",
    "\n",
    "For a change, we will be using the [Jester](http://eigentaste.berkeley.edu/dataset/) dataset, obtained from the [Jester Online Joke Recommender System](http://eigentaste.berkeley.edu/index.html). It has over 1.7 million continuous ratings (-10.00 to +10.00) of 150 jokes from 59,132 users: collected between November 2006 - May 2009. Our first step will be to download this dataset. Fortunately, `Surprise` has a built-in loader for the Jester dataset. Make sure you confirm that you want to download the dataset when prompted to do so."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise import Dataset\n",
    "\n",
    "\n",
    "# Load the Jester dataset (download it if needed),\n",
    "data = Dataset.load_builtin('jester')\n",
    "# split the data into 2 folds for cross-validation.\n",
    "data.split(n_folds=2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will need to train the k-Nearest Neighbors algorithm within Surprise on the Jester dataset (Check the [documentation](http://surprise.readthedocs.io/en/stable/) for `SVD`). For evaluation, Jester allows multiple metrics. You will need to use the `RMSE` and the `MAE` in this case. The training might take a few minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise import SVD\n",
    "from surprise import evaluate, print_perf\n",
    "\n",
    "# TODO: fill the code for evaluating the model based on SVD\n",
    "# We'll use the SVD algorithm.\n",
    "algo = ...\n",
    "\n",
    "# Evaluate performances of our algorithm on the dataset.\n",
    "perf = ...\n",
    "\n",
    "print_perf(perf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above code was hopefully short, and it's mainly for showing the power of the library. Now that you have trained and evaluated the recommendation algorithm, let's try to find the predicted rating for a single user and item."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uid = str(196)  # raw user id (as in the ratings file). They are **strings**!\n",
    "iid = str(98)  # raw item id (as in the ratings file). They are **strings**!\n",
    "\n",
    "# TODO get a prediction for user with uid and item iid\n",
    "pred = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are interested in knowing what the joke was for item 98, you can check the dataset. By default, the dataset will be downloaded in your home directory, under `$HOME/.surprise_data/jester/`. The file `jester_items.dat` has the text of the jokes. 😉\n",
    "\n",
    "Finally, feel free to explore the library further. It might come in handy for your future projects!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
